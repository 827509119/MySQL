# 参数文件

## 作用

告诉MySQL实例，启动时，在哪里可以找到数据库文件，并且指定哪些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。

mysql数据库的配置文件，包含了各类系统参数

## 参数文件类型

### Windows

> |               位置                |                     描述                     |
> | :-------------------------------: | :------------------------------------------: |
> | %WINDIR%\my.ini， %WINDIR%\my.cnf |         全局选项<br />echo %WINDIR%          |
> |       C:\my.ini， C:\my.cnf       |                   全局选项                   |
> |  BASEDIR\my.ini， BASEDIR\my.cnf  |  全局选项<br />BASEDIR表示MySQL基本安装目录  |
> |        defaults-extra-file        | 用指定的文件 --defaults-extra-file（如果有） |
> |   %APPDATA%\MySQL\.mylogin.cnf    | 登录路径选项（仅客户端）<br />echo %APPDATA  |

### Unix和类似Unix

> |        位置         |                             描述                             |
> | :-----------------: | :----------------------------------------------------------: |
> |     /etc/my.cnf     |                           全局选项                           |
> |  /etc/mysql/my.cnf  |                           全局选项                           |
> |  SYSCONFDIR/my.cnf  | SYSCONFDIR表示在构建MySQL时SYSCONFDIR 使用CMake选项指定的目录。默认情况下，这是etc位于内置安装目录下的目录 |
> | $MYSQL_HOME/my.cnf  |                 服务器特定的选项（仅服务器）                 |
> | defaults-extra-file |         用指定的文件 --defaults-extra-file（如果有）         |
> |      ~/.my.cnf      |                        用户特定的选项                        |
> |   ~/.mylogin.cnf    |             用户特定的登录路径选项（仅限客户端）             |

## 参数类型

### 动态参数(dynamic)

可以在Mysql运行实例中进行修改

### 静态参数(static)

整个运行过程中，不许修改。只读的。只能修改配置文件，并重启生效。如:开启二进制日志的 log_bin只能在 配置文件中指定

## 参数文件加载顺序

### 如何查看MySQL参数文件加载顺序

mysql --verbose --help | grep my.cnf

> 上边的两个列表中从上往下，下边的配置会覆盖上边相同的配置

---

# 日志文件

查看日志文件默认路径：

```
mysql> show variables like 'datadir';
+---------------+-----------------+
| Variable_name | Value           |
+---------------+-----------------+
| datadir       | /var/lib/mysql/ |
+---------------+-----------------+
1 row in set (0.00 sec)
```



## 错误日志

记录了mysql启动、运行、关闭过程

### 查看错误日志位置

show variables like 'log_err%';

## 慢查询日志 - slow query log

### 作用

记录执行超过指定时间值的SQL语句

### 查看慢日志是否开启 / 慢日志位置

```
mysql> show variables like '%slow%';
+---------------------------+--------------------------------------+
| Variable_name             | Value                                |
+---------------------------+--------------------------------------+
| log_slow_admin_statements | OFF                                  |
| log_slow_slave_statements | OFF                                  |
| slow_launch_time          | 2                                    |
| slow_query_log            | OFF                                  |
| slow_query_log_file       | /var/lib/mysql/4709e2f4ee4f-slow.log |
+---------------------------+--------------------------------------+
5 rows in set (0.00 sec)

mysql> set @@global.slow_query_log = ON;
Query OK, 0 rows affected (0.04 sec)

mysql> show variables like '%slow%';
+---------------------------+--------------------------------------+
| Variable_name             | Value                                |
+---------------------------+--------------------------------------+
| log_slow_admin_statements | OFF                                  |
| log_slow_slave_statements | OFF                                  |
| slow_launch_time          | 2                                    |
| slow_query_log            | ON                                   |
| slow_query_log_file       | /var/lib/mysql/4709e2f4ee4f-slow.log |
+---------------------------+--------------------------------------+
5 rows in set (0.01 sec)

```

### 满足什么条件会记录到慢查询日志中

1. 阈值：long_query_time，只有超过这个时间的sql才会被记录，等于这个值，不会被记录。
   默认为10秒。

   ```
   mysql> show variables like 'long_query_time';
   +-----------------+-----------+
   | Variable_name   | Value     |
   +-----------------+-----------+
   | long_query_time | 10.000000 |
   +-----------------+-----------+
   1 row in set (0.00 sec)
   ```

   现在改为200ms（改完之后再次查询没看到效果，退出重进之后，发现修改成功）

   ```
   mysql> set global long_query_time = 0.200000;
   Query OK, 0 rows affected (0.00 sec)
   
   mysql> show variables like 'long_query_time';
   +-----------------+-----------+
   | Variable_name   | Value     |
   +-----------------+-----------+
   | long_query_time | 10.000000 |
   +-----------------+-----------+
   1 row in set (0.00 sec)
   
   mysql> exit
   Bye
   root@4709e2f4ee4f:/# mysql -u root -proot
   Warning: Using a password on the command line interface can be insecure.
   Welcome to the MySQL monitor.  Commands end with ; or \g.
   Your MySQL connection id is 355
   Server version: 5.6.49 MySQL Community Server (GPL)
   
   Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
   
   Oracle is a registered trademark of Oracle Corporation and/or its
   affiliates. Other names may be trademarks of their respective
   owners.
   
   Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
   
   mysql> show variables like 'long_query_time';
   +-----------------+----------+
   | Variable_name   | Value    |
   +-----------------+----------+
   | long_query_time | 0.200000 |
   +-----------------+----------+
   1 row in set (0.00 sec)
   ```

   

2. sql语句不走索引也会被记录到慢日志中
   需要打开 log_queries_not_using_indexes，默认为关闭状态

   ```
   mysql> show variables like 'log_queries_not_using_indexes';
   +-------------------------------+-------+
   | Variable_name                 | Value |
   +-------------------------------+-------+
   | log_queries_not_using_indexes | OFF   |
   +-------------------------------+-------+
   1 row in set (0.00 sec)
   
   mysql> set global log_queries_not_using_indexes = ON;
   Query OK, 0 rows affected (0.00 sec)
   
   mysql> show variables like 'log_queries_not_using_indexes';
   +-------------------------------+-------+
   | Variable_name                 | Value |
   +-------------------------------+-------+
   | log_queries_not_using_indexes | ON    |
   +-------------------------------+-------+
   1 row in set (0.00 sec)
   ```

   另外还有一个参数，控制每分钟不走索引被记录到慢日志的sql的数量：0为不限制

   ```
   mysql> show variables like 'log_throttle_queries_not_using_indexes';
   +----------------------------------------+-------+
   | Variable_name                          | Value |
   +----------------------------------------+-------+
   | log_throttle_queries_not_using_indexes | 0     |
   +----------------------------------------+-------+
   1 row in set (0.00 sec)
   ```

### 测试慢日志记录

> 建表语句：show create table user1;
>
> CREATE TABLE `user1` (
>   `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键id',
>   `user_name` varchar(100) DEFAULT NULL COMMENT '用户名',
>   `user_age` tinyint(3) DEFAULT NULL COMMENT '用户年龄',
>   `user_password` varchar(100) DEFAULT NULL COMMENT '用户密码',
>   `user_sex` tinyint(1) DEFAULT NULL COMMENT '性别 1-男，0-女',
>   `user_province` varchar(32) DEFAULT NULL COMMENT '用户所在省',
>   `user_city` varchar(32) DEFAULT NULL COMMENT '用户所在城市',
>   `user_area` varchar(32) DEFAULT NULL COMMENT '用户所在区',
>   `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
>   `modified_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
>   PRIMARY KEY (`user_id`),
>   KEY `idx_user_name` (`user_name`),
>   KEY `idx_user_age` (`user_age`),
>   KEY `idx_province_city_area` (`user_province`,`user_city`,`user_area`)
> ) ENGINE=InnoDB AUTO_INCREMENT=223793 DEFAULT CHARSET=utf8;

1. （Navicat中）执行一个时间长的走索引的sql

   > - 首先看执行计划，是走索引的
   >
   > mysql> explain select * from user1 where user_age < 8;
   >
   > |  id  | select_type | table | type  | possible_keys |     key      | key_len | ref  | rows  |         Extra         |
   > | :--: | :---------: | :---: | :---: | :-----------: | :----------: | :-----: | :--: | :---: | :-------------------: |
   > |  1   |   SIMPLE    | user1 | range | idx_user_age  | idx_user_age |    2    | NULL | 35042 | Using index condition |
   >
   > 1 row in set (0.04 sec)
   >
   > mysql> select * from user1 where user_age < 8;
   > (为了排版省去一部分字段展示)
   >
   > | user_id | user_name | user_age | user_sex | user_province | user_city | user_area |
   > | :-----: | :-------: | :------: | :------: | :-----------: | :-------: | :-------: |
   > |  13698  |  颜难慧   |    3     |    0     |    河南省     |  泰安市   |  南岔区   |
   > |   ...   |    ...    |   ...    |   ...    |      ...      |    ...    |    ...    |
   >
   > 16961 rows in set (38.39 sec)

   

2. （Navicat中）执行一个不走索引的sql

   > mysql> explain select * from user1 where user_password = 'aa80452e65864e56afa335c31538870c';
   >
   > |  id  | select_type | table | type | possible_keys | key  | key_len | ref  |  rows  |    Extra    |
   > | :--: | :---------: | :---: | :--: | :-----------: | :--: | :-----: | :--: | :----: | :---------: |
   > |  1   |   SIMPLE    | user1 | ALL  |     NULL      | NULL |  NULL   | NULL | 208534 | Using where |
   >
   > 1 row in set (0.19 sec)
   >
   > mysql> select * from user1 where user_password = 'aa80452e65864e56afa335c31538870c';
   > (为了排版省去一部分字段展示)
   >
   > | user_id | user_name | user_age |          user_password           | user_province | user_city | user_area |
   > | :-----: | :-------: | :------: | :------------------------------: | :-----------: | :-------: | :-------: |
   > | 223621  |  和筵颠   |    7     | aa80452e65864e56afa335c31538870c |    山西省     | 平顶山市  |  榆次区   |
   >
   > 1 row in set (0.29 sec)

   

3. （Navicat中）再执行一个sql，跟第一个sql一样

   > select * from user1 where user_age < 12;
   > (为了排版省去一部分字段展示)
   >
   > | user_id | user_name | user_age | user_sex | user_province | user_city | user_area |
   > | :-----: | :-------: | :------: | :------: | :-----------: | :-------: | :-------: |
   > |  13698  |  颜难慧   |    3     |    0     |    河南省     |  泰安市   |  南岔区   |
   > |   ...   |    ...    |   ...    |   ...    |      ...      |    ...    |    ...    |

4. 查看详细的日志文件

   ```
   root@4709e2f4ee4f:/usr/bin# cat /var/lib/mysql/4709e2f4ee4f-slow.log 
   mysqld, Version: 5.6.49 (MySQL Community Server (GPL)). started with:
   Tcp port: 3306  Unix socket: /var/run/mysqld/mysqld.sock
   Time                 Id Command    Argument
   ...
   # Time: 200921  6:05:42
   # User@Host: root[root] @  [xxx.xxx.xx.xxx]  Id:   358
   # Query_time: 11.581630  Lock_time: 0.000100 Rows_sent: 16961  Rows_examined: 16961
   SET timestamp=1600668342;
   select * from user1 where user_age < 8;
   # Time: 200921  6:24:23
   # User@Host: root[root] @  [xxx.xxx.xx.xxx]  Id:   361
   # Query_time: 0.154447  Lock_time: 0.000114 Rows_sent: 1  Rows_examined: 210102
   SET timestamp=1600669463;
   select * from user1 where user_password = 'aa80452e65864e56afa335c31538870c';
   # Time: 200921  7:23:32
   # User@Host: root[root] @  [xxx.xxx.xx.xxx]  Id:   365
   # Query_time: 20.423910  Lock_time: 0.000076 Rows_sent: 25440  Rows_examined: 210102
   SET timestamp=1600673012;
   select * from user1 where user_age < 12;
   ...
   ```

   可以看到完整的sql保存在慢日志中。

5. 使用mysqldumpslow查看慢日志
   本处使用docker里的MySQL

   ```
   root@4709e2f4ee4f:/usr/bin# mysqldumpslow /var/lib/mysql/4709e2f4ee4f-slow.log 
   
   Reading mysql slow query log from /var/lib/mysql/4709e2f4ee4f-slow.log
   Count: 2  Time=16.00s (32s)  Lock=0.00s (0s)  Rows=21200.5 (42401), root[root]@[xxx.xxx.xx.xxx]
     select * from user1 where user_age < N
   
   Count: 1  Time=0.15s (0s)  Lock=0.00s (0s)  Rows=1.0 (1), root[root]@[xxx.xxx.xx.xxx]
     select * from user1 where user_password = 'S'
   ```

   通过显示内容，可发现一些信息

   - 执行时间上不太一致。（慢日志记录的是sql真正执行时间。其他客户端看到的时间，跟网络带宽有关）
   - mysqldumpslow后边，有一个默认的参数，按照平均查询时间(向下取整)来排序，递减排序
   - 该工具把数字格式化成 N ，string格式化成 S
   - Count：该类型的sql执行了几次。由以上可知，执行了两次
   - Time=16.00s (32s) ，其中，括号左边的16代表该类sql平均执行16秒，括号里的32s代表总执行时间为32秒。
   - Lock类似Time，代表锁的时间
   - Rows类似Time，代表返回行数
   - root[root]@[xxx.xxx.xx.xxx] ，其中xxx.xxx.xx.xxx为查询sql的客户端ip，此处未切换IP测试，暂时未知
   - 下边就是查询的sql

### mysqldumpslow的高级用法

> 查看mysqldumpslow 的一些参数
> root@4709e2f4ee4f:/usr/bin# mysqldumpslow --help
> Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]
>
> Parse and summarize the MySQL slow query log. Options are
>
>   --verbose    verbose
>   --debug      debug
>   --help       write this text to standard output
>
>   -v           verbose	//verbose：adj. 冗长的;啰唆的;唠叨的
>   -d           debug
>   -s ORDER     what to sort by (al, at, ar, c, l, r, t), 'at' is default		//根据什么来排序，'at'是默认的
>                 al: average lock time														 //平均锁时间
>                 ar: average rows sent													   //平均发送的行数时间
>                 at: average query time													  //平均查询时间
>                  c: count																			//总的行数
>                  l: lock time																		//总的锁时间
>                  r: rows sent																	  //总的发送行数
>                  t: query time  																  //总的查询时间
>   -r           reverse the sort order (largest last instead of first)			//颠倒排序顺序（最大的最后一个而不是第一个）
>   -t NUM       just show the top n queries											//返回指定 数量的慢查询日志
>   -a           don't abstract all numbers to N and strings to 'S'				//不把所有的数字抽象成N，字符串抽象成S
>   -n NUM       abstract numbers with at least n digits within names	//至少格式化NUM个数字？？
>   -g PATTERN   grep: only consider stmts that include this string		//grep：只考虑包含指定字符串的慢日志
>   -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),
>                default is '*', i.e. match all														//数据库服务器上 -slow.log
>   -i NAME      name of server instance (if using mysql.server startup script)	
> 																											//服务器实例的名称（如果使用mysql.server启动脚本）
>   -l           don't subtract lock time from total time								//不要从总时间中减去锁定时间

根据操作参数，使用mysqldumpslow 的高级用法

```
1、查看包含指定字符串的慢日志
    root@4709e2f4ee4f:/usr/bin# mysqldumpslow -g 'password' /var/lib/mysql/4709e2f4ee4f-slow.log

    Reading mysql slow query log from /var/lib/mysql/4709e2f4ee4f-slow.log
    Count: 1  Time=0.15s (0s)  Lock=0.00s (0s)  Rows=1.0 (1), root[root]@[xxx.xxx.xx.xxx]
      select * from user1 where user_password = 'S'
2、查询返回的总行数最多的两条记录
	root@4709e2f4ee4f:/usr/bin# mysqldumpslow -s r -t 2 /var/lib/mysql/4709e2f4ee4f-slow.log

    Reading mysql slow query log from /var/lib/mysql/4709e2f4ee4f-slow.log
    Count: 2  Time=16.00s (32s)  Lock=0.00s (0s)  Rows=21200.5 (42401), root[root]@[xxx.xxx.xx.xxx]
      select * from user1 where user_age < N

    Count: 1  Time=0.00s (0s)  Lock=0.00s (0s)  Rows=1000.0 (1000), root[root]@[xxx.xxx.xx.xxx]
      SELECT * FROM `lgt6`.`user1` LIMIT N, N

3、根据总的发送行数排序 - Rows括号里的数值
	root@4709e2f4ee4f:/usr/bin# mysqldumpslow -s r -n 2 /var/lib/mysql/4709e2f4ee4f-slow.log
	Reading mysql slow query log from /var/lib/mysql/4709e2f4ee4f-slow.log
    Count: 2  Time=16.00s (32s)  Lock=0.00s (0s)  Rows=21200.5 (42401), root[root]@[xxx.xxx.xx.xxx]
      select * from user1 where user_age < N

    Count: 1  Time=0.00s (0s)  Lock=0.00s (0s)  Rows=1000.0 (1000), root[root]@[xxx.xxx.xx.xxx]
      SELECT * FROM `lgt6`.`user1` LIMIT N, N

    Count: 3  Time=0.01s (0s)  Lock=0.00s (0s)  Rows=95.0 (285), root[root]@[xxx.xxx.xx.xxx]
      SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, COLUMN_TYPE FROM information_schema.COLUMNS WHERE TABLE_SCHEMA = 'S' ORDER BY TABLE_SCHEMA, TABLE_NAME

    Count: 3  Time=0.00s (0s)  Lock=0.00s (0s)  Rows=10.0 (30), root[root]@[xxx.xxx.xx.xxx]
      SELECT TABLE_SCHEMA, TABLE_NAME, TABLE_TYPE FROM information_schema.TABLES WHERE TABLE_SCHEMA = 'S' ORDER BY TABLE_SCHEMA, TABLE_TYPE

    Count: 1  Time=0.00s (0s)  Lock=0.00s (0s)  Rows=17.0 (17), root[root]@[xxx.xxx.xx.xxx]
      SELECT STATE AS `Status`, ROUND(SUM(DURATION),N) AS `Duration`, CONCAT(ROUND(SUM(DURATION)/N.N*N,N), 'S') AS `Percentage` FROM INFORMATION_SCHEMA.PROFILING WHERE QUERY_ID=N GROUP BY SEQ, STATE ORDER BY SEQ

    Count: 2  Time=0.00s (0s)  Lock=0.02s (0s)  Rows=3.0 (6), root[root]@[xxx.xxx.xx.xxx]
      SELECT COUNT(*) FROM information_schema.TABLES WHERE TABLE_SCHEMA = 'S'UNION SELECT COUNT(*) FROM information_schema.COLUMNS WHERE TABLE_SCHEMA = 'S'UNION SELECT COUNT(*) FROM information_schema.ROUTINES WHERE ROUTINE_SCHEMA = 'S'

```

### 慢查询日志的输出方式

修改日志输出格式，默认为file

```
mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | FILE  |
+---------------+-------+
1 row in set (0.00 sec)

mysql> set global log_output = 'TABLE';
Query OK, 0 rows affected (0.00 sec)

mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | TABLE |
+---------------+-------+
1 row in set, 1 warning (0.00 sec)

mysql> select * from user1 where user_age < 8;
(Navicat中执行sql,15.359s)
```

select * from mysql.slow_log;

|     start_time      |           user_host            | query_time | lock_time | rows_sent | rows_examined |  db  | last_insert_id | insert_id | server_id |                           sql_text                           | thread_id |
| :-----------------: | :----------------------------: | :--------: | :-------: | :-------: | :-----------: | :--: | :------------: | :-------: | :-------: | :----------------------------------------------------------: | :-------: |
| 2020-09-21 08:13:26 |   root[root] @ localhost []    |  00:00:00  | 00:00:00  |     0     |       0       | lgt6 |       0        |     0     |     0     |                 select * from mysql.slow_log                 |    372    |
| 2020-09-21 08:14:11 | root[root] @  [xxx.xxx.xx.xxx] |  00:00:00  | 00:00:00  |     0     |       0       | lgt6 |       0        |     0     |     0     | SELECT TABLE_NAME, CHECK_OPTION, IS_UPDATABLE, SECURITY_TYPE, DEFINER FROM INFORMATION_SCHEMA.VIEWS WHERE TABLE_SCHEMA = 'lgt6' ORDER BY TABLE_NAME ASC |    370    |
| 2020-09-21 08:14:24 | root[root] @  [xxx.xxx.xx.xxx] |  00:00:00  | 00:00:00  |   16961   |     16961     | lgt6 |       0        |     0     |     0     |            select * from user1 where user_age < 8            |    370    |
| 2020-09-21 08:14:30 | root[root] @  [xxx.xxx.xx.xxx] |  00:00:00  | 00:00:00  |     4     |      77       | lgt6 |       0        |     0     |     0     | SELECT QUERY_ID, SUM(DURATION) AS SUM_DURATION FROM INFORMATION_SCHEMA.PROFILING GROUP BY QUERY_ID |    370    |
| 2020-09-21 08:14:30 | root[root] @  [xxx.xxx.xx.xxx] |  00:00:00  | 00:00:00  |    17     |      128      | lgt6 |       0        |     0     |     0     | SELECT STATE AS `Status`, ROUND(SUM(DURATION),7) AS `Duration`, CONCAT(ROUND(SUM(DURATION)/0.000542*100,3), '') AS `Percentage` FROM INFORMATION_SCHEMA.PROFILING WHERE QUERY_ID=2 GROUP BY SEQ, STATE ORDER BY SEQ |    370    |

## 二进制日志

> 以下内容部分引自[mysql二进制日志总结](https://blog.csdn.net/demonson/article/details/80664141)

### 简介

MySQL的二进制日志（**binary log**）是一个二进制文件，**主要用于记录修改数据或有可能引起数据变更的MySQL语句**。（特殊情况，就算DML语句没有对数据库造成修改，也会被记录）。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。**二进制日志（binary log）主要用于数据库恢复和主从复制，以及审计（audit）操作。**

> 审计是对资料作出证据搜集及分析，以评估企业财务状况，然后就资料及一般公认准则之间的相关程度作出结论及报告。进行审计的人员必需有独立性及具相关专业知识。
>
> 简而言之，防止sql注入和不合业务逻辑的sql

### 参数控制

- log_bin控制二进制日志的开启、关闭
  查看系统变量log_bin，如果其值为OFF，表示没有开启二进制日志（binary log），如果需要开启二进制日志，则必须在my.cnf中[mysqld]下面添加log-bin [=DIR\[filename]] ，DIR参数指定二进制文件的存储路径；filename参数指定二级制文件的文件名。 其中filename可以任意指定，但最好有一定规范。系统变量log_bin是静态参数，不能动态修改的（因为它不是Dynamic Variable）。如下所示：

  ```
  mysql> show variables like 'log_bin';
  +---------------+-------+
  | Variable_name | Value |
  +---------------+-------+
  | log_bin       | OFF   |
  +---------------+-------+
  1 row in set, 1 warning (0.00 sec)
  
  mysql> set global log_bin = ON;
  ERROR 1238 (HY000): Variable 'log_bin' is a read only variable
  ```

  关闭MySQL服务，修改配置文件，重启MySQL

  ```
  [mysqld]
  log_bin=1
  server-id=1
  
  ---
  mysql5.7若不配置 server-id会报如下错
  ---
  [ERROR] You have enabled the binary log, but you haven’t provided the mandatory server-id. Please refer to the proper server start-up parameters documentation 
  2016-09-03T03:17:51.815890Z 0 [ERROR] Aborting
  ```

  如果在my.cnf里面只设置log_bin，但是不指定file_name，然后重启数据库。会自动生成日志文件。
  以下为查看二进制日志是否开启：

  ```
  mysql> show variables like '%log_bin%';
  +---------------------------------+------------------------+
  | Variable_name                   | Value                  |
  +---------------------------------+------------------------+
  | log_bin                         | ON                     |
  | log_bin_basename                | /var/lib/mysql/1       |
  | log_bin_index                   | /var/lib/mysql/1.index |
  | log_bin_trust_function_creators | OFF                    |
  | log_bin_use_v1_row_events       | OFF                    |
  | sql_log_bin                     | ON                     |
  +---------------------------------+------------------------+
  6 rows in set (0.00 sec)
  
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000001 |       143 |
  | 1.000002 |       120 |
  +----------+-----------+
  2 rows in set (0.00 sec)
  
  mysql> show master logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000001 |       143 |
  | 1.000002 |       120 |
  +----------+-----------+
  2 rows in set (0.00 sec)
  
  mysql> show master status;
  +----------+----------+--------------+------------------+-------------------+
  | File     | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
  +----------+----------+--------------+------------------+-------------------+
  | 1.000002 |      120 |              |                  |                   |
  +----------+----------+--------------+------------------+-------------------+
  1 row in set (0.00 sec)
  ```

### 二进制日志的切换

- **flush logs**

  ```
  mysql> show master status;
  +----------+----------+--------------+------------------+-------------------+
  | File     | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
  +----------+----------+--------------+------------------+-------------------+
  | 1.000002 |      120 |              |                  |                   |
  +----------+----------+--------------+------------------+-------------------+
  1 row in set (0.00 sec)
  
  mysql> flush logs;
  Query OK, 0 rows affected (0.05 sec)
  
  mysql> show master status;
  +----------+----------+--------------+------------------+-------------------+
  | File     | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
  +----------+----------+--------------+------------------+-------------------+
  | 1.000003 |      120 |              |                  |                   |
  +----------+----------+--------------+------------------+-------------------+
  1 row in set (0.00 sec)
  ```

- **重启MySQL服务也会切换一个新的二进制文件**

  ```
  [root@liuguotai ~]# docker ps
  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
  4709e2f4ee4f        mysql:5.6           "docker-entrypoint..."   4 weeks ago         Up 2 hours          0.0.0.0:3306->3306/tcp   mysql
  
  
  [root@liuguotai ~]# docker restart 4709e2f4ee4f
  4709e2f4ee4f
  
  ---
  重新进入MySQL，查询二进制日志
  ---
  mysql> show master status;
  +----------+----------+--------------+------------------+-------------------+
  | File     | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
  +----------+----------+--------------+------------------+-------------------+
  | 1.000004 |      120 |              |                  |                   |
  +----------+----------+--------------+------------------+-------------------+
  1 row in set (0.00 sec)
  ```

- **可以发现File 这一列的值，在递增。由一个 index 文件维护，里面记录了所有的日志文件**

  ```
  mysql> show variables like 'log_bin_index';
  +---------------+------------------------+
  | Variable_name | Value                  |
  +---------------+------------------------+
  | log_bin_index | /var/lib/mysql/1.index |
  +---------------+------------------------+
  1 row in set (0.00 sec)
  ```

  查看以下这个文件的内容：

  ```
  root@4709e2f4ee4f:/# vim /var/lib/mysql/1.index
  
  ./1.000001
  ./1.000002
  ./1.000003
  ./1.000004
  
  ---
  或者，通过命令查看目前所有的二进制文件
  ---
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000001 |       143 |
  | 1.000002 |       159 |
  | 1.000003 |       143 |
  | 1.000004 |       120 |
  +----------+-----------+
  4 rows in set (0.00 sec)
  ```

### 删除二进制日志文件

- **purge binary logs to xxx; 表示删除某个日志之前的所有二进制日志文件。这个命令会修改index中相关数据**

  ```
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000001 |       143 |
  | 1.000002 |       159 |
  | 1.000003 |       143 |
  | 1.000004 |       120 |
  +----------+-----------+
  4 rows in set (0.00 sec)
  
  mysql> purge binary logs to '1.000002';
  Query OK, 0 rows affected (0.00 sec)
  
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000002 |       159 |
  | 1.000003 |       143 |
  | 1.000004 |       120 |
  +----------+-----------+
  3 rows in set (0.00 sec)
  ```

  然后看看日志文件的目录，发现 之前的日志已被删除

  ```
  root@4709e2f4ee4f:/# ls /var/lib/mysql
  1.000002  1.000003  1.000004  1.index  4709e2f4ee4f-slow.log  auto.cnf	ib_logfile0  ib_logfile1  ibdata1  lgt6  mysql	performance_schema
  ```

- **清除某个时间点以前的二进制日志文件**

  ```
  mysql> purge binary logs before '2017-03-10 10:10:00';
  Query OK, 0 rows affected (0.00 sec)
  ```

- **清除7天前的二进制日志文件**

  ```
  mysql> purge master logs before date_sub( now(), interval 7 day);
  Query OK, 0 rows affected (0.00 sec)
  ```

- **清除所有的二进制日志文件（当前不存在主从复制关系）**

  ```
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000002 |       159 |
  | 1.000003 |       143 |
  | 1.000004 |       120 |
  +----------+-----------+
  3 rows in set (0.00 sec)
  
  mysql> reset master;
  Query OK, 0 rows affected (0.01 sec)
  
  mysql> show binary logs;
  +----------+-----------+
  | Log_name | File_size |
  +----------+-----------+
  | 1.000001 |       120 |
  +----------+-----------+
  1 row in set (0.00 sec)
  ```

- 另外，我们也可以设置**expire_logs_days**参数，设置自动清理，其默认值为0,表示不启用过期自动删除功能，如果启用了自动清理功能，表示超出此天数的二进制日志文件将被自动删除，自动删除工作通常发生在MySQL启动时或FLUSH日志时。

  ```
  mysql> show variables like 'expire_logs_days';
  +------------------+-------+
  | Variable_name    | Value |
  +------------------+-------+
  | expire_logs_days | 7     |
  +------------------+-------+
  1 row in set (0.01 sec)
  
  mysql> set global expire_logs_days=7;
  Query OK, 0 rows affected (0.00 sec)
  
  mysql> show variables like 'expire_logs_days';
  +------------------+-------+
  | Variable_name    | Value |
  +------------------+-------+
  | expire_logs_days | 7     |
  +------------------+-------+
  1 row in set (0.01 sec)
  ```

### 相关参数

- ***log_bin_basename***
  系统变量log_bin_basename是MySQL 5.6.2开始引入的。 它表示二进制日志文件名。也不能在my.cnf中配置，否则会报错

  ```
  mysql> show variables like 'log_bin_basename';
  +------------------+------------------+
  | Variable_name    | Value            |
  +------------------+------------------+
  | log_bin_basename | /var/lib/mysql/1 |
  +------------------+------------------+
  1 row in set (0.00 sec)
  ```

- ***log_bin_index***
  

系统变量log_bin_index是MySQL 5.6.4开始引入的。 它表示二进制日志的索引文件。该参数可以在my.cnf中设置。

  ```
  mysql> show variables like 'log_bin_index';
  +---------------+------------------------+
  | Variable_name | Value                  |
  +---------------+------------------------+
  | log_bin_index | /var/lib/mysql/1.index |
  +---------------+------------------------+
  1 row in set (0.00 sec)
  ```

- **log_bin_trust_function_creators**
  系统变量log_bin_trust_function_creators，默认为OFF，这个参数开启会限制存储过程、Function、触发器的创建。

  ```
  mysql> show variables like 'log_bin_trust_function_creators';
  +---------------------------------+-------+
  | Variable_name                   | Value |
  +---------------------------------+-------+
  | log_bin_trust_function_creators | OFF   |
  +---------------------------------+-------+
  1 row in set (0.00 sec)
  ```

- **sql_log_bin**
  系统变量sql_log_bin 用于控制会话级别二进制日志功能的开启或关闭，默认为ON，表示启用二进制日志功能。

  ```
  mysql> show variables like 'sql_log_bin';
  +---------------+-------+
  | Variable_name | Value |
  +---------------+-------+
  | sql_log_bin   | ON    |
  +---------------+-------+
  1 row in set (0.00 sec)
  ```

- ***expire_logs_days***
  

自动清除二进制日志的天数

- ***binlog_cache_size*** 
  

系统变量binlog_cache_size 表示为**每个客户端**分配binlog_cache_size大小的缓存，默认值32768。**二进制日志缓存使用的前提条件是服务器端使用了支持事务的引擎以及开启了bin log功能，它是MySQL用来提高binlog的效率而设计的一个用于短时间内临时缓存binlog数据的内存区域。**一般来说，如果我们的数据库中没有什么大事务，写入也不是特别频繁，2MB～4MB是一个合适的选择。但是如果我们的数据库大事务较多或多事务语句，写入量比较大，可适当调高binlog_cache_size。同时，我们可以通过binlog_cache_use 以及 binlog_cache_disk_use来分析设置的binlog_cache_size是否足够，是否有大量的binlog_cache由于内存大小不够而使用临时文件（binlog_cache_disk_use）来缓存了。

  所有未提交的二进制日志都会记录到这个缓存中，待事务commit后，再写到磁盘的二进制文件中。

  ```
  mysql> show variables like 'binlog_cache_size';
  +-------------------+-------+
  | Variable_name     | Value |
  +-------------------+-------+
  | binlog_cache_size | 32768 |
  +-------------------+-------+
  1 row in set (0.00 sec)
  
  mysql> show status like 'binlog%';
  +----------------------------+-------+
  | Variable_name              | Value |
  +----------------------------+-------+
  | Binlog_cache_disk_use      | 0     |
  | Binlog_cache_use           | 0     |
  | Binlog_stmt_cache_disk_use | 0     |
  | Binlog_stmt_cache_use      | 0     |
+----------------------------+-------+
  4 rows in set (0.00 sec)
  ```

- ***max_binlog_cache_size*** 
  

系统变量max_binlog_cache_size 二进制日志能够使用的最大cache内存大小。当执行多语句事务时，max_binlog_cache_size 如果不够大，系统可能会报出“Multi-statement transaction required more than ‘max_binlog_cache_size’ bytes of storage”的错误。

  ```
  mysql> show variables like 'max_binlog_cache_size';
  +-----------------------+----------------------+
  | Variable_name         | Value                |
  +-----------------------+----------------------+
  | max_binlog_cache_size | 18446744073709547520 |
  +-----------------------+----------------------+
  1 row in set (0.00 sec)
  ```

- **max_binlog_stmt_cache_size**
  max_binlog_cache_size针对事务语句，max_binlog_stmt_cache_size针对非事务语句，当我们发现Binlog_cache_disk_use或者Binlog_stmt_cache_disk_use比较大时就需要考虑增大cache的大小

  ```
  mysql> show variables like 'max_binlog_stmt_cache_size';
  +----------------------------+----------------------+
  | Variable_name              | Value                |
  +----------------------------+----------------------+
  | max_binlog_stmt_cache_size | 18446744073709547520 |
  +----------------------------+----------------------+
  1 row in set (0.01 sec)
  ```

- ***max_binlog_size***
  

系统变量max_binlog_size， 表示二进制日志的最大值，一般设置为512M或1GB，但不能超过1GB。该设置并不能严格控制二进制日志的大小，尤其是二进制日志比较靠近极限而又遇到一个比较大事务时， 为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的所有SQL都记录进当前日志，直到事务结束。

另外，超过该大小后，日志文件后缀会自动+1.

  ```
  mysql> show variables like 'max_binlog_size';
  +-----------------+------------+
  | Variable_name   | Value      |
  +-----------------+------------+
  | max_binlog_size | 1073741824 |
  +-----------------+------------+
  1 row in set (0.00 sec)
  ```

- **binlog_checksum **
  系统变量binlog_checksum 用作复制的主从校检。 NONE表示不生成checksum，CRC-32表示使用这个算法做校检。

  ```
  mysql> show variables like 'binlog_checksum';
  +-----------------+-------+
  | Variable_name   | Value |
  +-----------------+-------+
  | binlog_checksum | CRC32 |
  +-----------------+-------+
  1 row in set (0.00 sec)
  ```

- ***sync_binlog***
  

这个参数对于Mysql系统来说是至关重要的，它不仅影响到二进制日志文件对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性。

 sync_binlog=0，当事务提交后，Mysql仅仅是将binlog_cache中的数据写入binlog文件，但不执行fsync之类的磁盘同步指令通知文件系统将缓存刷新到磁盘，而是让Filesystem自行决定什么时候来做同步。MySQL中默认的设置是 sync_binlog=0，即不作任何强制性的磁盘刷新指令，这个设置性能是最好的，但风险也是最大的。一旦系统崩溃（Crash），在文件系统缓存中的所有二进制日志信息都会丢失。从而带来数据不完整问题。

 sync_binlog=n，表示每写缓冲N次，Mysql将执行一次fsync之类的磁盘同步指令，同时文件系统将Binlog文件缓存刷新到磁盘。

可以适当的调整sync_binlog， 在牺牲一定的一致性下，获取更高的并发和性能。建议设为1.

  ```
  mysql> show variables like 'sync_binlog';
  +---------------+-------+
  | Variable_name | Value |
  +---------------+-------+
  | sync_binlog   | 1     |
  +---------------+-------+
  1 row in set (0.00 sec)
  ```

- ***binlog_format***

指定二进制日志的类型。分别有STATEMENT、ROW、MIXED三种值。MySQL 5.7.6之前默认为STATEMENT模式。MySQL 5.7.7之后默认为ROW模式。这个参数主要影响主从复制。

  ```
  mysql>  show variables like 'binlog_format';
  +---------------+-----------+
  | Variable_name | Value     |
  +---------------+-----------+
  | binlog_format | STATEMENT |
  +---------------+-----------+
  1 row in set (0.00 sec)
  
  mysql>  set global binlog_format = 'STATEMENT';
  ```

复制的模式有下面几种：

  > 基于SQL语句的复制(statement-based replication, SBR)，
  >
  > 基于行的复制(row-based replication, RBR)，会占用比较大的磁盘空间。
  >
  > 混合模式复制(mixed-based replication, MBR)。
  >
  > 什么时候不得不使用 ROWS 方式？
  >
  > 1. 表的存储引擎为 NDB，这时对表的DML操作都会记录为ROW格式
  > 2. 使用了 UUID()、USER()、CURRENT_USER()等不确定函数
  > 3. 使用了INSERT DELAY语句
  > 4. 使用了用户自定义函数(UDF)
  > 5. 使用了临时表 （temporary table）

  相应地，二进制日志的格式也有三种：STATEMENT，ROW，MIXED。

- log-slave-update

  如果当前数据库是复制中的slave角色，则它不会将从master取得并执行的二进制文件写入到自己二进制日志文件中。如果需要写入，则需要设置 log-slave-update。如果需要搭建 master => slave => slave 此参数必须要。

### 查看二进制日志内容

> 本处数据库为新库，新建test库，新建user1表
>
> CREATE TABLE `user1` (
>   `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键id',
>   `user_name` varchar(100) DEFAULT NULL COMMENT '用户名',
>   `user_age` tinyint(3) DEFAULT NULL COMMENT '用户年龄',
>   `user_password` varchar(100) DEFAULT NULL COMMENT '用户密码',
>   `user_sex` tinyint(1) DEFAULT NULL COMMENT '性别 1-男，0-女',
>   `user_province` varchar(32) DEFAULT NULL COMMENT '用户所在省',
>   `user_city` varchar(32) DEFAULT NULL COMMENT '用户所在城市',
>   `user_area` varchar(32) DEFAULT NULL COMMENT '用户所在区',
>   `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
>   `modified_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
>   PRIMARY KEY (`user_id`),
>   KEY `idx_user_name` (`user_name`),
>   KEY `idx_user_age` (`user_age`),
>   KEY `idx_province_city_area` (`user_province`,`user_city`,`user_area`),
>   KEY `idx_sex` (`user_sex`)
> ) ENGINE=InnoDB AUTO_INCREMENT=223795 DEFAULT CHARSET=utf8;

- **show binlog events;**

  ```
  mysql> show binlog events;
  +----------+-----+----------------+-----------+-------------+---------------------------------------+
  | Log_name | Pos | Event_type     | Server_id | End_log_pos | Info                                  |
  +----------+-----+----------------+-----------+-------------+---------------------------------------+
  | 1.000001 |   4 | Format_desc    |         1 |         123 | Server ver: 5.7.31-log, Binlog ver: 4 |
  | 1.000001 | 123 | Previous_gtids |         1 |         154 |                                       |
  | 1.000001 | 154 | Stop           |         1 |         177 |                                       |
  +----------+-----+----------------+-----------+-------------+---------------------------------------+
  3 rows in set (0.00 sec)
  ```

  Pos:日志开始位置，End_log_pos:日志结束位置

- show binlog events in 'xxxxxxx'

  ```
  mysql> show master status;
  +----------+----------+--------------+------------------+-------------------+
  | File     | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
  +----------+----------+--------------+------------------+-------------------+
  | 1.000010 |     2612 |              |                  |                   |
  +----------+----------+--------------+------------------+-------------------+
  1 row in set (0.00 sec)
  
  mysql> INSERT INTO `user1`(`user_id`, `user_name`, `user_age`, `user_password`, `user_sex`, `user_province`, `user_city`, `user_area`, `create_time`, `modified_time`) VALUES (13717, '963', 33, '38451cbf6a8d4215a86048ed26ea5402', 1, '', '', '', '2020-08-18 15:45:08', '2020-08-18 15:45:08');
  Query OK, 1 row affected (0.02 sec)
  
  mysql> show binlog events in '1.000010';
  +----------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
  | Log_name | Pos | Event_type     | Server_id | End_log_pos | Info                                                                                                                                                                                                                                                                                                   |
  +----------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
  | 1.000010 |   4 | Format_desc    |         1 |         123 | Server ver: 5.7.31-log, Binlog ver: 4                                                                                                                                                                                                                                                                  |
  | 1.000010 | 123 | Previous_gtids |         1 |         154 |                                                                                                                                                                                                                                                                                                        |
  | 1.000010 | 154 | Anonymous_Gtid |         1 |         219 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS'                                                                                                                                                                                                                                                                   |
  | 1.000010 | 219 | Query          |         1 |         298 | BEGIN                                                                                                                                                                                                                                                                                                  |
  | 1.000010 | 298 | Query          |         1 |         654 | use `test`; INSERT INTO `user1`(`user_id`, `user_name`, `user_age`, `user_password`, `user_sex`, `user_province`, `user_city`, `user_area`, `create_time`, `modified_time`) VALUES (13717, '963', 33, '38451cbf6a8d4215a86048ed26ea5402', 1, '', '', '', '2020-08-18 15:45:08', '2020-08-18 15:45:08') |
  | 1.000010 | 654 | Xid            |         1 |         685 | COMMIT /* xid=18 */                                                                                                                                                                                                                                                                                    |
  +----------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
  6 rows in set (0.00 sec)
  ```

- **mysqlbinlog + 二进制日志绝对路径+文件名** 

  ```
  root@890276bf3194:/# mysqlbinlog /var/lib/mysql/1.000010
  /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;
  /*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;
  DELIMITER /*!*/;
  # at 4
  #200922  9:46:58 server id 1  end_log_pos 123 CRC32 0x49962389 	Start: binlog v 4, server v 5.7.31-log created 200922  9:46:58 at startup
  # Warning: this binlog is either in use or was not closed properly.
  ROLLBACK/*!*/;
  BINLOG '
  EshpXw8BAAAAdwAAAHsAAAABAAQANS43LjMxLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
  AAAAAAAAAAAAAAAAAAASyGlfEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQA
  AYkjlkk=
  '/*!*/;
  # at 123
  #200922  9:46:58 server id 1  end_log_pos 154 CRC32 0x0806bc20 	Previous-GTIDs
  # [empty]
  # at 154
  #200922  9:50:53 server id 1  end_log_pos 219 CRC32 0xca81a888 	Anonymous_GTID	last_committed=0	sequence_number=1	rbr_only=no
  SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;
  # at 219
  #200922  9:50:53 server id 1  end_log_pos 298 CRC32 0xe66a4371 	Query	thread_id=3	exec_time=0	error_code=0
  SET TIMESTAMP=1600768253/*!*/;
  SET @@session.pseudo_thread_id=3/*!*/;
  SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;
  SET @@session.sql_mode=1436549152/*!*/;
  SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;
  /*!\C latin1 *//*!*/;
  SET @@session.character_set_client=8,@@session.collation_connection=8,@@session.collation_server=8/*!*/;
  SET @@session.lc_time_names=0/*!*/;
  SET @@session.collation_database=DEFAULT/*!*/;
  BEGIN
  /*!*/;
  # at 298
  #200922  9:50:53 server id 1  end_log_pos 654 CRC32 0x01702e0b 	Query	thread_id=3	exec_time=0	error_code=0
  use `test`/*!*/;
  SET TIMESTAMP=1600768253/*!*/;
  INSERT INTO `user1`(`user_id`, `user_name`, `user_age`, `user_password`, `user_sex`, `user_province`, `user_city`, `user_area`, `create_time`, `modified_time`) VALUES (13717, '963', 33, '38451cbf6a8d4215a86048ed26ea5402', 1, '', '', '', '2020-08-18 15:45:08', '2020-08-18 15:45:08')
  /*!*/;
  # at 654
  #200922  9:50:53 server id 1  end_log_pos 685 CRC32 0x9b835679 	Xid = 18
  COMMIT/*!*/;
  SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;
  DELIMITER ;
  # End of log file
  /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;
  /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;
  ```

- **mysqlbinlog + 二进制日志绝对路径+文件名 > test.sql**
  在哪里执行，就会在当前路径下生成sql文件

  ```
  mysqlbinlog /var/lib/mysql/1.000010 > test.sql
  
  root@890276bf3194:/# ls
  bin  boot  dev	docker-entrypoint-initdb.d  entrypoint.sh  etc	home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  test.sql  tmp  usr	var
  
  root@890276bf3194:/# mysqlbinlog /var/lib/mysql/1.000010 > test.sql
  。。。内容与上边一致，此处省略
  ```

- **如果是 ROW 格式，则使用 mysqlbinlog -vv 二进制日志绝对路径+文件名**
  （注意此处，是  - V V 不是 - W）

### **开启二进制日志影响性能吗？**

开启MySQL的二进制日志会影响服务器性能吗？答案是会有一些性能损耗，但是性能开销非常小，1%左右（slightly slower），另外，开启binlog带来的好处要远远超过带来的性能开销。官方文档的介绍如下所示：

**Running a server with binary logging enabled makes performance slightly slower. However, the benefits of the binary log in enabling you to set up replication and for restore operations generally outweigh this minor performance decrement.**

## 查询日志

> 以下部分内容引自[Mysql查询日志](https://www.cnblogs.com/ray-mr-huang/p/10466692.html)

**MySQL的查询日志记录了所有MySQL数据库请求的信息**。**无论这些请求是否得到了正确的执行**。默认文件名为hostname.log。默认情况下MySQL查询日志是关闭的。**生产环境，如果开启MySQL查询日志，对性能还是有蛮大的影响的。**另外很多时候，MySQL慢查询日志基本可以定位那些出现性能问题的SQL，所以MySQL查询日志应用的场景其实不多，有点鸡肋的感觉，它跟SQL Server中的profiler有点类似，但是这个不能跟踪某个会话、用户、客户端。它只能对整个数据库进行跟踪。MySQL查询日志本身比较简单，网上介绍的不多，官方资料也就那么短短一篇。

### 参数控制

- MySQL中的参数**general_log**用来控制开启、关闭MySQL查询日志,参数**general_log_file**用来控制查询日志的位置。所以如果你要判断MySQL数据库是否开启了查询日志，可以使用下面命令。general_log为ON表示开启查询日志，OFF表示关闭查询日志。
- **log_output**控制日志输出格式，**FILE**输出为文件，默认地址可进行查看。**TABLE**输出为表格，再**mysql.general_log**中

```
mysql> show variables like '%general_log%';
+------------------+---------------------------------+
| Variable_name    | Value                           |
+------------------+---------------------------------+
| general_log      | OFF                             |
| general_log_file | /var/lib/mysql/4709e2f4ee4f.log |
+------------------+---------------------------------+
2 rows in set, 1 warning (0.00 sec)

mysql> set global general_log = ON;
Query OK, 0 rows affected (0.01 sec)

mysql> show variables like '%general_log%';
+------------------+---------------------------------+
| Variable_name    | Value                           |
+------------------+---------------------------------+
| general_log      | ON                              |
| general_log_file | /var/lib/mysql/4709e2f4ee4f.log |
+------------------+---------------------------------+
2 rows in set, 1 warning (0.00 sec)

mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | FILE  |
+---------------+-------+
1 row in set, 1 warning (0.00 sec)
```

> 简单看看日志记录 时间采用格林尼治时间，加8个小时为北京时间
>
> C:\Program Files\MySQL\MySQL Server 5.7\bin\mysqld.exe, Version: 5.7.28-log (MySQL Community Server (GPL)). started with:
> TCP Port: 3306, Named Pipe: MySQL
> Time                 Id Command    Argument
> 2020-09-22T02:01:20.582539Z	   32 Query	show variables like '%log%'
> 2020-09-22T02:01:40.078835Z	   32 Query	select * from user1 where user_id = 135643
> 2020-09-22T02:01:59.132562Z	   33 Init DB	mysql
> 2020-09-22T02:01:59.133062Z	   33 Query	SELECT * FROM `mysql`.`general_log` LIMIT 0, 1000
> 2020-09-22T02:01:59.135145Z	   34 Init DB	mysql
> 2020-09-22T02:01:59.135483Z	   34 Query	SHOW COLUMNS FROM `mysql`.`general_log`
> 2020-09-22T02:01:59.136795Z	   33 Query	SHOW TABLE STATUS LIKE 'general_log'
> 2020-09-22T02:01:59.138354Z	   33 Query	SHOW CREATE TABLE `mysql`.`general_log`
> 2020-09-22T02:02:25.570595Z	   35 Connect	root@localhost on  using SSL/TLS
> 2020-09-22T02:02:25.571317Z	   35 Query	select @@version_comment limit 1
> 2020-09-22T02:02:38.818566Z	   35 Query	show variables like '%log%'
> 2020-09-22T02:03:07.598350Z	   35 Query	SELECT DATABASE()
> 2020-09-22T02:03:07.598705Z	   35 Init DB	testmybatis

关闭查询日志记录（性能影响太大）

```
mysql> set global general_log = OFF;
Query OK, 0 rows affected (0.01 sec)

mysql> show variables like '%general_log%';
+------------------+---------------------------------+
| Variable_name    | Value                           |
+------------------+---------------------------------+
| general_log      | OFF                             |
| general_log_file | /var/lib/mysql/4709e2f4ee4f.log |
+------------------+---------------------------------+
2 rows in set, 1 warning (0.00 sec)
```



---

# socket文件

用UNIX域本地连接MySQL时，所需要的文件

---

# pid文件

MySQL实例进程ID的文件

---

# MySQL表文件

## MYISAM的表文件

### **表定义文件：表名.frm**

### **索引文件：表名.MYI**

### **数据文件：表名.MYD**

## InnoDB的表文件

### **表定义文件：表名.frm**

### **共享表空间文件：ibdata1**

```
# 查看默认的表空间文件及一些信息

mysql> show variables like 'innodb_data_file_path';
+-----------------------+------------------------+
| Variable_name         | Value                  |
+-----------------------+------------------------+
| innodb_data_file_path | ibdata1:12M:autoextend |
+-----------------------+------------------------+
1 row in set, 1 warning (0.00 sec)
```

可以在my.cnf配置文件里配置多个表空间文件：

```
[mysqld]
innodb_data_file_path = /db/ibdata:2000M;/db2/ibdata2:2000M:autoextend
```

用两个文件组成共享表空间，若这两个文件在不同的磁盘上，	磁盘的负载将会被平均，可以提升数据库的整体性能。

autoextend：表示用完了指定的大小空间后，会自增。

### **私有表空间文件：表名.ibd**
开启参数 innodb_file_per_table 后，会为没一张表提供一个独立的表空间，用于存放**数据、索引、插入缓冲BITMAP**。默认为开启状态

```
mysql> show variables like 'innodb_file_per_table';
+-----------------------+-------+
| Variable_name         | Value |
+-----------------------+-------+
| innodb_file_per_table | ON    |
+-----------------------+-------+
1 row in set, 1 warning (0.00 sec)
```

### **重做日志（redo log）**

#### （一）概念及作用

redo log叫做**重做**日志，记录InnoDB的事务日志：**物理格式的日志**，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。如，偏移量80，写‘ddd’操作。

**作用：用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。**

#### （二）redo log 的组成部分

redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。

![1.4.2.redo log buffer和 redo log](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.2.redo%20log%20buffer%E5%92%8C%20redo%20log.jpg)

#### （三）内存中的redo log buffer

在概念上，innodb通过***force log at commit\***机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。

为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。

也就是说，从redo log buffer写日志到磁盘的redo log file中，过程如下： 

![1.4.3.redo log buffer 和 redo log示意图2](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.3.redo%20log%20buffer%20%E5%92%8C%20redo%20log%E7%A4%BA%E6%84%8F%E5%9B%BE2.png)

> 在此处需要注意一点，一般所说的log file并不是磁盘上的物理日志文件，而是操作系统缓存中的log file，官方手册上的意思也是如此(例如：With a value of 2, the contents of the **InnoDB log buffer are written to the log file** after each transaction commit and **the log file is flushed to disk approximately once per second**)。但说实话，这不太好理解，既然都称为file了，应该已经属于物理文件了。所以在本文后续内容中都以os buffer或者file system buffer来表示官方手册中所说的Log file，然后log file则表示磁盘上的物理日志文件，即log file on disk。
>
> 另外，之所以要经过一层os buffer，是因为open日志文件的时候，open没有使用O_DIRECT标志位，该标志位意味着绕过操作系统层的os buffer，IO直写到底层存储设备。不使用该标志位意味着将日志进行缓冲，缓冲到了一定容量，或者显式fsync()才会将缓冲中的刷到存储设备。使用该标志位意味着每次都要发起系统调用。比如写abcde，不使用o_direct将只发起一次系统调用，使用o_object将发起5次系统调用。——从 InnoDB 架构中可以看出来。



#### （四）磁盘上的 redo log file 文件

每个InnoDB至少有一个重做日志组（**log group**），一组中包含两个文件。即，默认只有一个组， ib_logfile0 和 ib_logfile1 。将不同的文件组放在不同的磁盘上，可以提升性能。 ib_logfile0 和 ib_logfile1 文件大小相同，以循环写入的方式运行。0写满时，会切换到1，1写满后，会切换到0。默认在InnoDB引擎的数据文件目录下

##### 磁盘上的 logfile 文件相关参数

1. **innodb_log_file_size**
   用于指定重做日志的大小。在InnoDB1.2.x之前，重做日志大小不得大于等于4G，1.2.x之后，将该限制扩大到512G

   ```
   mysql> show variables like 'innodb_log_file_size';
   +----------------------+----------+
   | Variable_name        | Value    |
   +----------------------+----------+
   | innodb_log_file_size | 50331648 |
   +----------------------+----------+
   1 row in set, 1 warning (0.00 sec)
   ```

2. **innodb_log_files_in_group**
   一个组内重做日志的数量，默认为2

   ```
   mysql> show variables like 'innodb_log_files_in_group';
   +---------------------------+-------+
   | Variable_name             | Value |
   +---------------------------+-------+
   | innodb_log_files_in_group | 2     |
   +---------------------------+-------+
   1 row in set, 1 warning (0.00 sec)
   ```

3. **innodb_log_group_home_dir**
   日志文件组所在的路径，即MySQL data文件的路径

   ```
   mysql> show variables like 'innodb_log_group_home_dir';
   +---------------------------+-------+
   | Variable_name             | Value |
   +---------------------------+-------+
   | innodb_log_group_home_dir | .\    |
   +---------------------------+-------+
   1 row in set, 1 warning (0.00 sec)
   ```

##### 磁盘上的 logfile 文件大小限制

重做日志的大小，对InnoDB的性能有很大影响。
设置的过大，恢复的时候，需要很长时间；设置的过小，一个大事务会频繁切换文件，发生asyn checkpoint，发生性能抖动。

#### （五）日志块(log block)

innodb存储引擎中，redo log以块为单位进行存储的，每个块占512字节，这称为redo log block。所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的。

> 512字节为系统底层一个扇区的最小存储单位。

每个redo log block由3部分组成：**日志块头、日志块尾和日志主体**。其中日志块头占用12字节，日志块尾占用8字节，所以每个redo log block的日志主体部分只有512-12-8=492字节。

![1.4.5.日志块(log block)组成](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.5.%E6%97%A5%E5%BF%97%E5%9D%97(log%20block)%E7%BB%84%E6%88%90.png)

因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。

日志块头包含4部分：

-  log_block_hdr_no：(4字节)该日志块在redo log buffer中的位置ID。
-  log_block_hdr_data_len：(2字节)该log block中已记录的log大小。写满该log block时为0x200，表示512字节。
-  log_block_first_rec_group：(2字节)该log block中第一个log的开始偏移位置。
-  lock_block_checkpoint_no：(4字节)写入检查点信息的位置。

关于log block块头的第三部分 log_block_first_rec_group ，因为有时候一个数据页产生的日志量超出了一个日志块，这是需要用多个日志块来记录该页的相关日志。例如，某一数据页产生了552字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用60个字节，那么对于第二个日志块来说，它的第一个log的开始位置就是73字节(60+12)。如果该部分的值和 log_block_hdr_data_len 相等，则说明该log block中没有新开始的日志块，即表示该日志块用来延续前一个日志块。

日志尾只有一个部分： log_block_trl_no ，该值和块头的 log_block_hdr_no 相等。

上面所说的是一个日志块的内容，在redo log buffer或者redo log file on disk中，由很多log block组成。如下图：

![1.4.6.多个log block的组成](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.6.%E5%A4%9A%E4%B8%AAlog%20block%E7%9A%84%E7%BB%84%E6%88%90.png)

#### （六）log group和redo log file

log group表示的是redo log group，一个组内由多个大小完全相同的redo log file组成。（上文中 ib_logfile0 和 ib_logfile1为默认的一个组）。组内redo log file的数量由变量 innodb_log_files_group 决定，默认值为2，即两个redo log file。这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组，但是可以通过变量 innodb_log_group_home_dir 来定义组的目录，redo log file都放在这个目录下，默认是在datadir下。

```mysql
mysql> show global variables like "innodb_log%";
+-----------------------------+----------+
| Variable_name               | Value    |
+-----------------------------+----------+
| innodb_log_buffer_size      | 8388608  |
| innodb_log_compressed_pages | ON       |
| innodb_log_file_size        | 50331648 |
| innodb_log_files_in_group   | 2        |
| innodb_log_group_home_dir   | ./       |
+-----------------------------+----------+

[root@xuexi data]# ll /mydata/data/ib*
-rw-rw---- 1 mysql mysql 79691776 Mar 30 23:12 /mydata/data/ibdata1
-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 /mydata/data/ib_logfile0
-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 /mydata/data/ib_logfile1
```

可以看到在默认的数据目录下，有两个ib_logfile开头的文件，它们就是log group中的redo log file，而且它们的大小完全一致且等于变量 innodb_log_file_size 定义的值。第一个文件ibdata1是在没有开启 innodb_file_per_table 时的共享表空间文件，对应于开启 innodb_file_per_table 时的.ibd文件。也就是说如果没有开启 innodb_file_per_table ，redo log会放到共享表空间中。

在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式循环轮训写入。即先在第一个log file（即ib_logfile0）的尾部追加写，直到满了之后向第二个log file（即ib_logfile1）写。当第二个log file满了会清空一部分第一个log file继续写入。

由于是将log buffer中的日志刷到log file，所以在log file中记录日志的方式也是log block的方式。

在每个组的第一个redo log file中，前2KB记录4个特定的部分，从2KB之后才开始记录log block。除了第一个redo log file中会记录，log group中的其他log file不会记录这2KB，但是却会腾出这2KB的空间。如下：

![log group和redo log file](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.7.log%20group%E5%92%8Credo%20log%20file.png)

这2KB中的内容如下：

|      名称       | 大小（字节） |
| :-------------: | :----------: |
| log file header |     512      |
|   checkpoint1   |     512      |
|       空        |     512      |
|   checkpoint2   |     512      |



redo log file的大小对innodb的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写redo log的时候循环切换redo log file。

两个checkpoint的重要作用：

- 两个检查点块交替写入检查点，保证有一个正确的检查点可以用。

- 检查点块中最重要的四个字段：

- - log_checkpoint_no。检查点序号。每生成一个检查点，序号加1.
  - **log_checkpoint_lsn。检查点lsn。要与其他地方的 LSN 进行比较**
  - log_checkpoint_offset。检查点lsn的文件空间偏移lsn_offset。
  - log_checkpoint_buf_size。log.buf的size。

#### （七）redo log的格式

因为innodb存储引擎存储数据的单元是页(和SQL Server中一样)，所以redo log也是基于页的格式来记录的。默认情况下，innodb的页大小是16KB(由 innodb_page_size 变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。**即，如果某条记录被修改了，那么redo log中，只有这一条记录，而不是这条记录所在的完整数据页。**

其中log block中492字节的部分是log body，该log body的格式分为4部分：

- redo_log_type：占用1个字节，表示redo log的日志类型。
- space：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。
- page_no：表示页的偏移量，同样是压缩过的。
- redo_log_body表示每个重做日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。

如下图，分别是insert和delete大致的记录方式。

![1.4.8.redo log的格式](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.8.redo%20log%E7%9A%84%E6%A0%BC%E5%BC%8F.png)

#### （八）什么时候产生redo log？什么时候日志刷盘？

事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便不断写入redo log文件中。

之所以说重做日志是在事务开始之后逐步写入磁盘的重做日志文件，而不一定是事务提交才写入重做日志。原因就是，重做日志有一个缓冲区Innodb_log_buffer,Innodb存储引擎先将重做日志写入innodb_log_buffer中，再以一定频率刷新到磁盘。log buffer中未刷到磁盘的日志称为脏日志(**dirty log**)。

![1.4.0.redo log的写入过程](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.0.redo%20Log%E5%86%99%E5%85%A5%E8%BF%87%E7%A8%8B.jpg)

##### **会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘**

     　　1. **Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。**
     　　2. **每个事务提交时会将重做日志刷新到重做日志文件。受参数 innodb_flush_log_at_trx_commit 控制**
     　　3. **当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件**

由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。
　　因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。
　　另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：
　　即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。从重做日志缓冲往磁盘写入时，是按512字节也就是一个扇区的大小写入的。因为扇区是最小的写入单位，因此可以保证写入必定成功。因此不需要Double Write。
　　这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。

##### **参数 innodb_flush_log_at_trx_commit 的含义，默认为1**

- **0，代表当提交事务时，并不将事务的重做日志写入磁盘上的日志文件，而是等待主线程每秒执行 fsyns 操作，将重做日志刷新到磁盘的重做日志文件中**
- **1，每次事务commit时，必须调用 fsync 操作，将重做日志缓冲同步写到磁盘；建议设为1**
- **2， 代表事务提交时，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk，故有丢失风险**

![1.4.4.innodb_flush_log_at_trx_commit参数的意义](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.4.innodb_flush_log_at_trx_commit%E5%8F%82%E6%95%B0%E7%9A%84%E6%84%8F%E4%B9%89.png)

在主从复制结构中，要保证事务的持久性和一致性，需要对日志相关变量设置为如下：

- **如果启用了二进制日志，则设置sync_binlog=1，即每提交一次事务同步写到磁盘中。**
- **总是设置innodb_flush_log_at_trx_commit=1，即每提交一次事务都写到磁盘中。**

上述两项变量的设置保证了：每次提交事务都写入二进制日志和事务日志，并在提交时将它们刷新到磁盘中。



#### （九）数据页刷盘的规则及checkpoint

内存中(buffer pool)未刷到磁盘的数据称为**脏数据(dirty data)**。由于数据和日志都以页的形式存在，所以**脏页表示脏数据和脏日志**。

上一节介绍了日志是何时刷到磁盘的，不仅仅是日志需要刷盘，脏数据页也一样需要刷盘。

**在innodb中，数据刷盘的规则只有一个：checkpoint。**但是触发checkpoint的情况却有几种。**不管怎样，checkpoint触发后，会将buffer中脏数据页和脏日志页都刷到磁盘。**

innodb存储引擎中checkpoint分为两种：

- sharp checkpoint：在重做redo log文件(例如切换日志文件)的时候，将所有已记录到redo log中对应的脏数据刷到磁盘。
- fuzzy checkpoint：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘。有以下几种情况会触发该检查点：
  - master thread checkpoint：由master线程控制，**每秒或每10秒**刷入一定比例的脏页到磁盘。
  - flush_lru_list checkpoint：从MySQL5.6开始可通过 innodb_page_cleaners 变量指定专门负责脏页刷盘的page cleaner线程的个数，该线程的目的是为了保证lru列表有可用的空闲页。
  - async/sync flush checkpoint：同步刷盘还是异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘
  - dirty page too much checkpoint：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。too much的比例由变量 innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的百分之75后，就强制刷一部分脏页到磁盘。

由于刷脏页需要一定的时间来完成，所以记录检查点的位置是在每次刷盘结束之后才在redo log中标记的。

> MySQL停止时是否将脏数据和脏日志刷入磁盘，由变量innodb_fast_shutdown={ 0|1|2 }控制，默认值为1，即停止时只做一部分purge，忽略大多数flush操作(但至少会刷日志)，在下次启动的时候再flush剩余的内容，实现fast shutdown。

#### （十）什么时候释放redo log

当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

#### （十一）InnoDB的恢复行为

在启动innodb的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。当实例从崩溃中恢复时，需要将活跃的事务从undo中提取出来，对于ACTIVE状态的事务直接回滚，对于Prepare状态的事务，如果该事务对应的binlog已经记录，则提交，否则回滚事务。

因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如二进制日志)要快很多。而且，innodb自身也做了一定程度的优化，让恢复速度变得更快。

重启innodb时，checkpoint表示已经完整刷到磁盘上data page上的LSN，因此恢复时仅需要恢复从checkpoint开始的日志部分。例如，当数据库在上一次checkpoint的LSN为10000时宕机，且事务是已经提交过的状态。启动数据库时会检查磁盘中数据页的LSN，如果数据页的LSN小于日志中的LSN，则会从检查点开始恢复。

![1.4.10.InnoDB恢复的例子.jpg](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.10.InnoDB%E6%81%A2%E5%A4%8D%E7%9A%84%E4%BE%8B%E5%AD%90.jpg)

还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度。这时候一宕机，数据页中记录的LSN就会大于日志页中的LSN，在重启的恢复过程中会检查到这一情况，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。

另外，事务日志具有幂等性，所以多次操作得到同一结果的行为在日志中只记录一次。而二进制日志不具有幂等性，多次操作会全部记录下来，在恢复的时候会多次执行二进制日志中的记录，速度就慢得多。例如，某记录中id初始值为2，通过update将值设置为了3，后来又设置成了2，在事务日志中记录的将是无变化的页，根本无需恢复；而二进制会记录下两次update操作，恢复时也将执行这两次update操作，速度比事务日志恢复更慢。

#### 举例说明

##### 1.以下用一个从银行账户投资理财的例子来说明 redo log buffer、redo log、脏页刷新。

![1.6.5.银行账户例子](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.6.5.%E9%93%B6%E8%A1%8C%E8%B4%A6%E6%88%B7%E4%BE%8B%E5%AD%90.jpg)

```mysql
start transaction;
select balance from bank where name="zhangsan" for update; 
// 生成 重做日志 balance=600 
update bank set balance = balance - 400;  
// 生成 重做日志 amount=400 
update finance set amount = amount + 400; 
commit;
```

下面显示完整的步骤：

![1.6.6.redo log记录详细步骤](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.6.6.redo%20log%E8%AE%B0%E5%BD%95%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4.jpg)

由上可知：

- mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Boffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做**缓冲池和磁盘之间的同步**。
- 当脏页还未从缓冲池刷新到磁盘，服务器宕机，则缓冲池中数据丢失。这时redo log 的作用就体现出来了。下次服务器启动后，InnoDB会识别并恢复对应的数据，写到磁盘的 .ibd文件中。

##### 2. 举例说明 checkpoint 和 write point的关系

（1）《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。

如果有人要赊账或者还账的话，掌柜一般有两种做法：

一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；

另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。

在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。

这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？

（2）同样，在MySQL里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。

（3）而粉板和账本配合的整个过程，其实就是MySQL里经常说到的**WAL技术**，WAL的全称是Write-Ahead Logging，它的关键点就是**先写日志，再写磁盘，**也就是先写粉板，等不忙的时候再写账本。

具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。

（4）与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![1.4.11.chekpoint和writepoint的例子](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.11.checkpoint%E5%92%8Cwritepoint%E7%9A%84%E4%BE%8B%E5%AD%90.png)

**write pos****是当前记录的位置**，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。**checkpoint****是当前要擦除的位置**，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个**能力称为****crash-safe****。**

要理解**crash-safe**这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。

#### 总结：

redo log是用来恢复数据的 用于保障，已提交事务的持久化特性

### 回滚日志 Undo log

#### （一）了解几个概念

##### undo

在事务的整个生命周期中维护的数据，记录所有更改，以便在回滚操作时可以撤消这些更改。它存储在系统表空间(在MySQL 5.7或更早版本中)的undo日志中，或者存储在单独的undo表空间中。从MySQL 8.0开始，默认情况下，undo日志驻留在undo表空间中。

##### undo log buffer

同 redo log buffer一样，在内存中，有一个区域，用于存放undo log buffer

撤消日志被分割成单独的部分:**插入撤消缓冲区**和**更新撤消缓冲区**。

##### undo log

**存储由活动事务修改的数据副本的区域。**如果另一个事务需要查看原始数据(作为一致的读操作的一部分)，则从该存储区域检索未修改的数据。

在MySQL 5.6和5.7中，你可以使用innodb_undo_tablespaces变量让undo日志驻留在undo表空间中，它可以放在另一个存储设备上，比如SSD。在MySQL 8.0中，undo日志驻留在两个默认的undo表空间中，它们是在MySQL初始化时创建的，另外的undo表空间可以使用CREATE undo TABLESPACE语法创建。

##### undo log segment

撤消日志的集合。撤销日志段存在于回滚段中。撤消日志段可以包含来自多个事务的撤消日志。undo log段一次只能被一个事务使用，但是在事务提交或回滚时释放它之后可以重用。也可以称为“撤销段”。

##### undo tablespace

撤消表空间包含撤消日志。撤消日志存在于撤消日志段中，而撤消日志段包含在回滚段中。回滚段通常位于system表空间中。在MySQL 5.6中，回滚段可以驻留在undo表空间中。在MySQL 5.6和5.7中，undo表空间的数量是由innodb_undo_tablespaces配置选项控制的。在MySQL 8.0中，当初始化MySQL实例时，会创建两个默认的undo表空间，并且可以使用CREATE undo TABLESPACE语法创建额外的undo表空间。

#### （二）简介

在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。Undo记录中存储的是老版本数据，当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作（例如[bug#69812](http://bugs.mysql.com/bug.php?id=69812)）。

大多数对数据的变更操作包括INSERT/DELETE/UPDATE，其中INSERT操作在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除（谁会对刚插入的数据有可见性需求呢！！），而对于UPDATE/DELETE则需要维护多版本信息，在InnoDB里，UPDATE和DELETE操作产生的Undo日志被归成一类，即update_undo。

undo log和redo log记录物理日志不一样，它是逻辑日志。**可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。**

当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。

**undo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。**

另外，**undo log也会产生redo log**，因为undo log也要实现持久性保护。

#### （三）作用

**undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。**

- 提供回滚
- 多个行版本控制(MVCC)

#### （四）存储方式

innodb存储引擎对undo的管理采用段的方式。**rollback segment**称为回滚段，每个回滚段中有**1024个undo log segment**。

在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持128*1024个undo操作，还可以通过变量 innodb_undo_logs (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。

为了保证事务并发操作时，在写各自的undo log时不产生冲突，InnoDB采用回滚段的方式来维护undo log的并发写入和持久化。回滚段实际上是一种 Undo 文件组织方式，每个回滚段又有多个undo log slot。具体的文件组织方式如下图所示：

![1.4.13.undo log文件组织方式](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.13.undo%20log%E6%96%87%E4%BB%B6%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F.png)

上图展示了基本的Undo回滚段布局结构，其中:

1. rseg0预留在系统表空间ibdata中;
2. rseg 1~rseg 32这32个回滚段存放于临时表的系统表空间中;
3. rseg33~ 则根据配置存放到独立undo表空间中（如果没有打开独立Undo表空间，则存放于ibdata中）

如果我们使用独立Undo tablespace，则总是从第一个Undo space开始轮询分配undo 回滚段。大多数情况下这是OK的，但假设我们将回滚段的个数从33开始依次递增配置到128，就可能导致所有的回滚段都存放在同一个undo space中。(参考函数trx_sys_create_rsegs 以及 [bug#74471](http://bugs.mysql.com/bug.php?id=74471))

每个回滚段维护了一个段头页，在该page中又划分了1024个slot(TRX_RSEG_N_SLOTS)，每个slot又对应到一个undo log对象，因此**理论上InnoDB最多支持 96 * 1024个普通事务。ibtemp1文件中还有32个回滚段，加起来一共为 128.**

#### （五）关键结构体

为了便于管理和使用undo记录，在内存中维持了如下关键结构体对象：

1. 所有回滚段都记录在`trx_sys->rseg_array`，数组大小为128，分别对应不同的回滚段；
2. rseg_array数组类型为trx_rseg_t，用于维护回滚段相关信息；
3. 每个回滚段对象trx_rseg_t还要管理undo log信息，对应结构体为trx_undo_t，使用多个链表来维护trx_undo_t信息;
4. 事务开启时，会专门给他指定一个回滚段，以后该事务用到的undo log页，就从该回滚段上分配;
5. 事务提交后，需要purge的回滚段会被放到purge队列上(`purge_sys->purge_queue`)。

各个结构体之间的联系如下：

![1.4.14.undo log关键结构体](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.14.undo%20log%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%84%E4%BD%93.png)

> 关于分配回滚段、使用回滚段、写入undo log，参考[阿里数据库月报2015/04/01](http://mysql.taobao.org/monthly/2015/04/01/)

#### （六）purge线程

当事务提交的时候，innodb不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。**(MVCC的影响，不能立即删除undo log)**

**但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。**

通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)

- delete操作实际上不会直接删除，而是将数据行中打上delete flag，标记为删除，最终的删除操作是purge线程完成的。
- update分为两种情况：update的列是否是主键列。
  - 如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。
  - 如果是主键列，update分两部执行：先删除该行，再插入一行目标行。

#### （七）group commit

为了提高性能，通常会将有关联性的多个数据修改操作放在一个事务中，这样可以避免对每个修改操作都执行完整的持久化操作。这种方式，可以看作是人为的组提交(group commit)。

除了将多个操作组合在一个事务中，记录binlog的操作也可以按组的思想进行优化：将多个事务涉及到的binlog一次性flush，而不是每次flush一个binlog。

事务在提交的时候不仅会记录事务日志，还会记录二进制日志，但是它们谁先记录呢？二进制日志是MySQL的上层日志，先于存储引擎的事务日志被写入。

在MySQL5.6以前，当事务提交(即发出commit指令)后，MySQL接收到该信号进入commit prepare阶段；进入prepare阶段后，立即写内存中的二进制日志，写完内存中的二进制日志后就相当于确定了commit操作；然后开始写内存中的事务日志；最后将二进制日志和事务日志刷盘，它们如何刷盘，分别由变量 sync_binlog 和 innodb_flush_log_at_trx_commit 控制。

但因为要保证二进制日志和事务日志的一致性，在提交后的prepare阶段会启用一个**prepare_commit_mutex**锁来保证它们的顺序性和一致性。但这样会导致开启二进制日志后group commmit失效，特别是在主从复制结构中，几乎都会开启二进制日志。

在MySQL5.6中进行了改进。提交事务时，在存储引擎层的上一层结构中会将事务按序放入一个队列，队列中的第一个事务称为leader，其他事务称为follower，leader控制着follower的行为。虽然顺序还是一样先刷二进制，再刷事务日志，但是机制完全改变了：删除了原来的prepare_commit_mutex行为，也能保证即使开启了二进制日志，group commit也是有效的。

MySQL5.6中分为3个步骤：**flush阶段、sync阶段、commit阶段。**

![1.4.12.group commit图示](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.12.group%20commit%E5%9B%BE%E7%A4%BA.png)

- flush阶段：向内存中写入每个事务的二进制日志。
- sync阶段：将内存中的二进制日志刷盘。若队列中有多个事务，那么仅一次fsync操作就完成了二进制日志的刷盘操作。这在MySQL5.6中称为BLGC(binary log group commit)。
- commit阶段：leader根据顺序调用存储引擎层事务的提交，由于innodb本就支持group commit，所以解决了因为锁 prepare_commit_mutex 而导致的group commit失效问题。

在flush阶段写入二进制日志到内存中，但是不是写完就进入sync阶段的，而是要等待一定的时间，多积累几个事务的binlog一起进入sync阶段，等待时间由变量 binlog_max_flush_queue_time 决定，默认值为0表示不等待直接进入sync，设置该变量为一个大于0的值的好处是group中的事务多了，性能会好一些，但是这样会导致事务的响应时间变慢，所以建议不要修改该变量的值，除非事务量非常多并且不断的在写入和更新。

进入到sync阶段，会将binlog从内存中刷入到磁盘，刷入的数量和单独的二进制日志刷盘一样，由变量 sync_binlog 控制。

当有一组事务在进行commit阶段时，其他新事务可以进行flush阶段，它们本就不会相互阻塞，所以group commit会不断生效。当然，group commit的性能和队列中的事务数量有关，如果每次队列中只有1个事务，那么group commit和单独的commit没什么区别，当队列中事务越来越多时，即提交事务越多越快时，group commit的效果越明显。

---

# LSN

## 什么是 LSN ?

LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，lsn占用8个字节。LSN的值会随着日志的写入而逐渐增大。

## 根据 LSN 能获得什么信息？

1. 数据页的版本信息。
2. 写入的日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量。
3. 可知道检查点的位置。

## LSN 存在的位置

LSN不仅存在于**redo log**中，还存在于**数据页**中，在每个数据页的头部，有一个*fil_page_lsn*记录了当前页最终的LSN值是多少。通过数据页中的LSN值和redo log中的LSN值比较，如果页中的LSN值小于redo log中LSN值，则表示数据丢失了一部分，这时候可以通过redo log的记录来恢复到redo log中记录的LSN值时的状态。

## 查看 LSN 信息

```mysql
mysql> show engine innodb status;

---
LOG
---
Log sequence number 2290689669
Log flushed up to   2290689669
Pages flushed up to 2290689669
Last checkpoint at  2290689660
0 pending log flushes, 0 pending chkp writes
10 log i/o's done, 0.00 log i/o's/second
```

其中：

- **log sequence number就是当前的redo log(in buffer)中的lsn；**
- **log flushed up to是刷到redo log file on disk中的lsn；**
- **pages flushed up to是已经刷到磁盘数据页上的LSN；**
- **last checkpoint at是上一次检查点所在位置的LSN。**

## 举个例子

执行多条DML语句：

1. 首先修改内存中(buffer pool)的数据页，并在数据页中记录LSN，暂且称之为data_in_buffer_lsn；
2. 并且在修改数据页的同时(几乎是同时)向redo log in buffer中写入redo log，并记录下对应的LSN，暂且称之为redo_log_in_buffer_lsn；
3. 写完buffer中的日志后，当触发了日志刷盘的几种规则时，会向redo log file on disk刷入重做日志，并在该文件中记下对应的LSN，暂且称之为redo_log_on_disk_lsn；
4. 数据页不可能永远只停留在内存中，在某些情况下，会触发checkpoint来将内存中的脏页(数据脏页和日志脏页)刷到磁盘，所以会在本次checkpoint脏页刷盘结束时，在redo log中记录checkpoint的LSN位置，暂且称之为checkpoint_lsn。
5. 要记录checkpoint所在位置很快，只需简单的设置一个标志即可，但是刷数据页并不一定很快，例如这一次checkpoint要刷入的数据页非常多。也就是说要刷入所有的数据页需要一定的时间来完成，中途刷入的每个数据页都会记下当前页所在的LSN，暂且称之为data_page_on_disk_lsn。

详细说明如下图：

![1.4.9.LSN变更图](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.9.LSN%E5%8F%98%E6%9B%B4%E5%9B%BE.png)

上图中，从上到下的横线分别代表：时间轴、buffer中数据页中记录的LSN(data_in_buffer_lsn)、磁盘中数据页中记录的LSN(data_page_on_disk_lsn)、buffer中重做日志记录的LSN(redo_log_in_buffer_lsn)、磁盘中重做日志文件中记录的LSN(redo_log_on_disk_lsn)以及检查点记录的LSN(checkpoint_lsn)。

假设在最初时(12:0:00)所有的日志页和数据页都完成了刷盘，也记录好了检查点的LSN，这时它们的LSN都是完全一致的。

假设此时开启了一个事务，并立刻执行了一个update操作，执行完成后，buffer中的数据页和redo log都记录好了更新后的LSN值，假设为110。这时候如果执行 show engine innodb status 查看各LSN的值，即图中①处的位置状态，结果会是：

```
log sequence number(110) > log flushed up to(100) = pages flushed up to = last checkpoint at
```

之后又执行了一个delete语句，LSN增长到150。等到12:00:01时，触发redo log刷盘的规则(其中有一个规则是 innodb_flush_log_at_timeout 控制的默认日志刷盘频率为1秒)，这时redo log file on disk中的LSN会更新到和redo log in buffer的LSN一样，所以都等于150，这时 show engine innodb status ，即图中②的位置，结果将会是：

```
log sequence number(150) = log flushed up to > pages flushed up to(100) = last checkpoint at
```

再之后，执行了一个update语句，缓存中的LSN将增长到300，即图中③的位置。

假设随后检查点出现，即图中④的位置，正如前面所说，检查点会触发数据页和日志页刷盘，但需要一定的时间来完成，所以在数据页刷盘还未完成时，检查点的LSN还是上一次检查点的LSN，但此时磁盘上数据页和日志页的LSN已经增长了，即：

```
log sequence number > log flushed up to 和 pages flushed up to > last checkpoint at
```

但是log flushed up to和pages flushed up to的大小无法确定，因为日志刷盘可能快于数据刷盘，也可能等于，还可能是慢于。但是checkpoint机制有保护数据刷盘速度是慢于日志刷盘的：当数据刷盘速度超过日志刷盘时，将会暂时停止数据刷盘，等待日志刷盘进度超过数据刷盘。

等到数据页和日志页刷盘完毕，即到了位置⑤的时候，所有的LSN都等于300。

随着时间的推移到了12:00:02，即图中位置⑥，又触发了日志刷盘的规则，但此时buffer中的日志LSN和磁盘中的日志LSN是一致的，所以不执行日志刷盘，即此时 show engine innodb status 时各种lsn都相等。

随后执行了一个insert语句，假设buffer中的LSN增长到了800，即图中位置⑦。此时各种LSN的大小和位置①时一样。

随后执行了提交动作，即位置⑧。默认情况下，提交动作会触发日志刷盘，但不会触发数据刷盘，所以 show engine innodb status 的结果是：

```
log sequence number = log flushed up to > pages flushed up to = last checkpoint at
```

最后随着时间的推移，检查点再次出现，即图中位置⑨。但是这次检查点不会触发日志刷盘，因为日志的LSN在检查点出现之前已经同步了。假设这次数据刷盘速度极快，快到一瞬间内完成而无法捕捉到状态的变化，这时 show engine innodb status 的结果将是各种LSN相等。

---

# 二进制日志文件 和 重做日志 之间的区别

1. 记录的范围不同
   - binlog，是基于MySQL数据库的，记录InnoDB、MYISAM等所有存储引擎的修改记录。
   - redo log，只记录跟InnoDB有关的事务日志
2. 记录的内容不同
   - binlog是逻辑日志，记录的是 ROW 或 STATEMENT ，具体的操作内容，或完整的sql。
   - redo log是物理日志，记录的是页的修改信息。例如：偏移量80，写‘ddd’操作。
3. 写入时间不同
   - binlog，只在事务提交前进行写入，不论事务多大，只写入一次
   - redo log，在事务进行过程中，不断被写入重做日志文件中。
     ![1.4.1.bin log和redo log写入的差异.png](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.1.bin%20log%E5%92%8Credo%20log%E5%86%99%E5%85%A5%E7%9A%84%E5%B7%AE%E5%BC%82.png)
   - 上图中可见，bin log只对事务记录一次。redo log 会不断记录事务内容。*T1 *T2 *T3表示事务提交时的日志。
4. 日志文件本身
   - binlog：MySQL服务重启、FLUSH LOGS、超过文件大小都会切换新的日志文件。文件名会递增+1
   - redo log，默认只有一个组，组内有两个重做日志，ib_logfile0 和 id_logfile1。循环写入，不会增加
5. 释放时间不同
   - binlog：binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。默认为0，不自动删除
   - redo log：对应事务的脏页刷新到磁盘后，该事务所占的空间就可以被覆盖。可以理解为被释放。Write指针会覆盖这段空间。
6. 文件大小限制
   - binlog的最大限制不严格，假设临近最大值，来了一个大事务，此时不会截断该事务的日志。会完整的记录到二进制文件中。允许超过最大限制。
   - redo log是循环利用的，所以，一旦超过文件限定大小，便切换另一个重做日志
7. 作用不同
   - binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的，主要用于主从复制、POING-IN-TIME的恢复和审计
   - redo log是保证事务的持久性的，是事务层面的。
8. 恢复数据的效率不同
   - redo log是记录页的修改信息，恢复效率高于bin log
9. 幂等性
   - 事务日志具有幂等性，所以多次操作得到同一结果的行为在日志中只记录一次。
   - 而二进制日志不具有幂等性，多次操作会全部记录下来，在恢复的时候会多次执行二进制日志中的记录，速度就慢得多。
   - 例如，某记录中id初始值为2，通过update将值设置为了3，后来又设置成了2，在事务日志中记录的将是无变化的页，根本无需恢复；而二进制会记录下两次update操作，恢复时也将执行这两次update操作，速度比事务日志恢复更慢。

# 日志文件的其他问题

1. **关于事务提交时，redo log和binlog的写入顺序：**
   		为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，
      　　MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。
      		但实际上，redo log会提交两次，第一次只是prepare阶段，并未真正提交。下一步中如果binlog保存失败，redolog是提交不了的。binlog是集群主从复制的主要参与者，而redolog是changebuffer的记录者，如果他们两不一致，那集群主从复制就没办法实现，因为数据太容易混乱了。
      		所以是先写bin log 后写 redo log。
   
2. **redo log是事务在执行过程中不断写入的，假如我事务回滚了，undo log肯定会被删除，那redo是不是也得删除？**

3. **redo log一开始被写到缓存中，master thread每秒会刷新到磁盘，一秒内事务回滚，会删缓存吗？**

   

# 举个例子 - bin log、redo log、undo log写入顺序

首先说明一个update的顺序

1. 首先在事务当中修改了一个数据
2. 修改的数据更新到了Buffer Pool当中
3. 修改的这步操作保存到了 Log Buffer当中(包含redo 和 undo)，2 3几乎同步
4. 提交事务。提交事务时内部有很多步骤，比如提交时，要求日志刷盘完成后才能完成提交。
   而且提交事务不保证数据刷盘，脏数据只有在遇到checkpoint时才会刷盘，但事务提交可以保证redo log刷盘。在刷盘之前，对同样数据的查询都来自于内存。
   而且，checkpoint也会触发脏日志刷盘，而且还有其它的机制触发日志刷盘。所以，日志刷盘的频率高于数据刷盘。

举里说明

1.  创建表的语句和更新的语句这个表的创建语句，这个表有一个主键ID和一个整型字段c：

    

   mysql> create table T(ID int primary key, c int);

   如果要将ID=2这一行的值加1，SQL语句就会这么写：

   mysql> update T set c=c+1 where ID=2;

    

   更新语句也是按照前面的逻辑架构的语句重新走一遍的。

   

   首先语句前要先连接数据库，这是连接器的工作。

    

   在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表T上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。

    

   接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用ID这个索引。然后，执行器负责具体执行，找到这一行，然后更新。

    

   与查询流程不一样的是，更新流程还涉及两个重要的日志模块：**redo log****（重做日志）和 binlog****（归档日志）。**如果接触MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log和binlog在设计上有很多有意思的地方，这些设计思路也可以用到自己的程序里。

2. 重做日志：redo log（1）《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。

   如果有人要赊账或者还账的话，掌柜一般有两种做法：

   一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；

   另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。

   在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。

   这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？

   （2）同样，在MySQL里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。

   （3）而粉板和账本配合的整个过程，其实就是MySQL里经常说到的**WAL技术**，WAL的全称是Write-Ahead Logging，它的关键点就是**先写日志，再写磁盘，**也就是先写粉板，等不忙的时候再写账本。

   具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

   如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。

   （4）与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

   ![1.4.11.chekpoint和writepoint的例子](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.11.checkpoint%E5%92%8Cwritepoint%E7%9A%84%E4%BE%8B%E5%AD%90.png)

   **write pos****是当前记录的位置**，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。**checkpoint****是当前要擦除的位置**，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

   write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

   有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个**能力称为****crash-safe****。**

   要理解**crash-safe**这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。

3. 二进制日志 bin log
   （1）MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板**redo log**是InnoDB引擎特有的日志，而**Server层也有自己的日志，称为binlog（归档日志）。**

    

   （2）因为最开始MySQL里并没有InnoDB引擎。MySQL*自带的引擎是MyISAM*，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档**。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。

4. 详细流程
   执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

    

   执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

    

   引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

    

   执行器生成这个操作的binlog，并把binlog写入磁盘。

    

   执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

    

   update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。
   ![1.4.15.update详细流程图](https://github.com/asdbex1078/MySQL/blob/master/mysql-image/1.4.15.update%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

   最后三部是将redo log的写入拆成了两个步骤：prepare和commit，这就是"两阶段提交"。

5. 两阶段提交两阶段提交是为了让两份日志保持一致

    

   理解这个问题主要的方式就是如何让数据恢复到15天内上的某个时间点上呢？

    

   binlog会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。

    

   当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

    

   首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；

   然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。

   这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。

6. 继续理解两阶段提交由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

    

   仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？

    

   先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。

   但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。

   然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。

    

   先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。

    

   可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。

    

   你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？

    

   其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。

    

   简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

7. 总结MySQL里面最重要的两个日志，即物理日志redo log和逻辑日志binlog。

    

   redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。

    

   sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。

    

   MySQL日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使不做数据库内核开发，日常开发中也有可能会用到。

> 参考网站：
>
> 1. [详解redo log 和 undo log](https://www.cnblogs.com/f-ck-need-u/p/9010872.html)
> 2. [InnoDB undo log漫游](http://mysql.taobao.org/monthly/2015/04/01/)
> 3. [MySQL中一条更新语句是如何执行的](https://www.cnblogs.com/wangchunli-blogs/p/10393139.html)